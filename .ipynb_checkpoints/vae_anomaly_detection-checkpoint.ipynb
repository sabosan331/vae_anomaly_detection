{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = (128,128,1)\n",
    "latent_dim = 32\n",
    "\n",
    "def make_vae(latent_size, kl_coeff=1.0):\n",
    "    \n",
    "    ## Encoder #################################################################################\n",
    "    encoder_input = keras.Input(shape=img_shape)\n",
    "    x = layers.Conv2D(8,4,padding='same',activation='relu',strides=(2,2))(encoder_input)\n",
    "    x = layers.Conv2D(16,4,padding='same',activation='relu',strides=(2,2))(x)\n",
    "    x = layers.Conv2D(24,4,padding='same',activation='relu',strides=(2,2))(x)\n",
    "    x = layers.Conv2D(32,4,padding='same',activation='relu',strides=(2,2))(x)\n",
    "    shape_before_flattening = K.int_shape(x) # フラット前の構造を保存\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    \n",
    "    z_mean = layers.Dense(latent_dim,name='z_mean')(x)\n",
    "    z_log_sigma = layers.Dense(latent_dim)(x)\n",
    "    \n",
    "    ## Latent Dim Sampling\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim) , mean = 0 , stddev=1. )\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "        \n",
    "    encoder = Model(encoder_input,z_mean, name='encoder') # z_mean is neccesary not z\n",
    "    encoder.summary()\n",
    "    ############################################################################################\n",
    "\n",
    "    ## Decoder #################################################################################\n",
    "    z = layers.Lambda(sampling, output_shape=(latent_size,))([z_mean, z_log_sigma])\n",
    "    decoder_input = layers.Input(K.int_shape(z)[1:])\n",
    "    x = layers.Dense(np.prod(shape_before_flattening[1:]),activation='relu')(decoder_input)\n",
    "    x = layers.Reshape(shape_before_flattening[1:])(x)\n",
    "    x = layers.Conv2DTranspose(32,4,padding='same',activation='relu',strides=(2,2) )(x)\n",
    "    x = layers.Conv2DTranspose(24,4,padding='same',activation='relu',strides=(2,2) )(x)\n",
    "    x = layers.Conv2DTranspose(16,4,padding='same',activation='relu',strides=(2,2) )(x)\n",
    "    x = layers.Conv2DTranspose(8,4,padding='same',activation='relu',strides=(2,2) )(x)\n",
    "    x = layers.Conv2D(1,3,padding='same',activation='sigmoid')(x)\n",
    "    decoder = Model(decoder_input,x)\n",
    "    decoder.summary()\n",
    "    ############################################################################################\n",
    "    \n",
    "    # define VAE\n",
    "    z_decoded = decoder(z_mean)\n",
    "    vae = Model(encoder_input,z_decoded)\n",
    "    vae.summary()\n",
    "        \n",
    "    def vae_loss(y_true, y_pred):\n",
    "        \n",
    "        recon_loss = K.sum(K.square(y_true-y_pred), axis=[1,2])\n",
    "        kl_loss = - 0.5 * K.sum(1 + 2*z_log_sigma - K.square(z_mean) - K.square(K.exp(z_log_sigma)), axis=-1)\n",
    "        return recon_loss + kl_coeff*kl_loss\n",
    "    \n",
    "    return encoder, decoder, vae, vae_loss\n",
    "\n",
    "# model定義\n",
    "encoder, decoder, vae, vae_loss = make_vae(32, kl_coeff=1.)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss, metrics=[])\n",
    "\n",
    "data_OK = np.load(\"./data/capsule_OK_katahou.npy\")\n",
    "data_NG = np.load(\"./data/capsule_NG_yarinaosi.npy\")\n",
    "\n",
    "# scaling 0 to 1\n",
    "data_OK = data_OK.astype('float32') / 255.\n",
    "data_OK = data_OK.transpose(0,2,3,1) # transpose\n",
    "\n",
    "data_NG = data_NG.astype('float32') / 255.\n",
    "data_NG = data_NG.transpose(0,2,3,1) # transpose\n",
    "\n",
    "# train, test split\n",
    "n_train = int(data_OK.shape[0]*0.6)\n",
    "X_train = data_OK[0:n_train:]\n",
    "\n",
    "n_val = int(data_OK.shape[0]*0.2)\n",
    "X_val_OK  = data_OK[n_train:n_train+n_val:]\n",
    "X_test_OK = data_OK[n_train+n_val::]\n",
    "\n",
    "# n_test = int( len(data_NG)*0.6 )\n",
    "X_test_NG  = data_NG[:]\n",
    "\n",
    "print(\"OK sample shape\",data_OK.shape)\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test_OK.shape\", X_test_OK.shape)\n",
    "print(\"X_val_OK.shape\",X_val_OK.shape)\n",
    "print(\"X_test_NG.shape\",X_test_NG.shape)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen= ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True\n",
    "    rotation_range=3, # 90°まで回転\n",
    "    width_shift_range=0.05, # 水平方向にランダムでシフト\n",
    "    #height_shift_range=0.1, # 垂直方向にランダムでシフト\n",
    "    #channel_shift_range=50.0, # 色調をランダム変更\n",
    "    #shear_range=0.39, # 斜め方向(pi/8まで)に引っ張る\n",
    "    horizontal_flip=True) # 水平方向にランダムで反転\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "_train_size = X_train.shape[0]\n",
    "_batch_size = 16\n",
    "_itr_size = 1500\n",
    "\n",
    "print('trainin_data : %d \\\n",
    "      \\nbatch_size   : %d \\\n",
    "      \\niter_size : %d \\\n",
    "      \\nvirtual_epoch : % d ' % (_train_size, _batch_size, _itr_size, _itr_size / (_train_size / _batch_size)))\n",
    "\n",
    "      itr=0\n",
    "train_loss_running,val_loss_running=0,0\n",
    "train_loss, val_loss = [],[]\n",
    "\n",
    "val_judge = float('inf') # oneday change this\n",
    "# infinite loop, so break using virtural epoch\n",
    "for x_batch in datagen.flow(x=X_train, y=None, batch_size=32,shuffle=True):\n",
    "    \n",
    "    # train using one bathc\n",
    "    result = vae.fit(x = x_batch, y=x_batch , verbose=0,validation_data=(X_val_OK,X_val_OK))\n",
    "    \n",
    "    # caluculate train_loss and val_loss\n",
    "    val_loss_running = result.history['val_loss'][0] / _batch_size\n",
    "    train_loss.append( result.history['loss'][0] / _batch_size)\n",
    "    val_loss.append( val_loss_running )\n",
    "\n",
    "    # best_model save after 80% train loop\n",
    "    if val_loss_running < val_judge and int(0.8 * _itr_size) < itr:\n",
    "        \n",
    "        print(\" model save, val_loss :\", val_loss_running)\n",
    "        val_judge = val_loss_running        \n",
    "        encoder.save('encoder_best.h5',include_optimizer=False)\n",
    "        decoder.save('decoder_best.h5',include_optimizer=False)\n",
    "    \n",
    "    \n",
    "    if itr % 100== 0:\n",
    "        print('-------------iteration-------------', itr)\n",
    "    if itr > _itr_size:\n",
    "        break\n",
    "        \n",
    "    itr = itr+1\n",
    "\n",
    "\n",
    "# load best model\n",
    "encoder_best = keras.models.load_model('encoder_best.h5', compile=False)\n",
    "decoder_best = keras.models.load_model('decoder_best.h5', compile=False)\n",
    "\n",
    "# encode and decode\n",
    "encode_test_OK = encoder_best.predict(X_test_OK)\n",
    "decode_test_OK = decoder_best.predict(encode_test_OK)\n",
    "encode_test_NG = encoder_best.predict(X_test_NG)\n",
    "decode_test_NG = decoder_best.predict(encode_test_NG)\n",
    "\n",
    "\n",
    "# plot loss and acc\n",
    "plt.plot( train_loss, label=\"training\")\n",
    "plt.plot( val_loss, label=\"validation\")\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Mean Absolute Error\n",
    "# OK\n",
    "arr_mae_OK = []\n",
    "diff_OK = (X_test_OK - decode_test_OK)\n",
    "diff_OK = np.absolute(diff_OK)\n",
    "for i in range(len(diff_OK)):\n",
    "    arr_mae_OK.append(np.sum(diff_OK[i,:,:,0] / diff_OK[i,:,:,0].size ))\n",
    "\n",
    "# NG\n",
    "arr_mae_NG = []\n",
    "diff_NG = (X_test_NG - decode_test_NG)\n",
    "diff_NG = np.absolute(diff_NG)\n",
    "for i in range(len(diff_NG)):\n",
    "    #print(np.sum(diff_NG[i,:,:,0]) , diff_NG[i,:,:,0].size )\n",
    "    arr_mae_NG.append(np.sum(diff_NG[i,:,:,0] / diff_NG[i,:,:,0].size ))\n",
    "    \n",
    "print(diff_OK[0,:,:,0].size)\n",
    "print(diff_NG[0,:,:,0].size)\n",
    "print(128*128)\n",
    "\n",
    "print( len(arr_mae_OK) )\n",
    "print( len(arr_mae_NG) )\n",
    "th = np.min(arr_mae_NG)\n",
    "print(th,np.max(arr_mae_OK))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12.0, 12.0))\n",
    "\n",
    "row,col = 3, 3\n",
    "id_res = 1\n",
    "for r in range(0,row):\n",
    "    for c in range(0,col):\n",
    "        ax = fig.add_subplot(row,col ,id_res)\n",
    "        ax.imshow( diff_OK[id_res,:,:,0] )\n",
    "        ax.tick_params(labelbottom=False, labelleft=False, direction='in')\n",
    "        mae = np.sum( diff_OK[id_res,:,:,0]) / diff_OK[id_res,:,:,0].size\n",
    "        ax.set_xlabel( '{:.3f}'.format(mae),size=15)\n",
    "        id_res = id_res + 1 # 画像ID\n",
    "plt.show()\n",
    "#plt.savefig('res_diff.png', facecolor='#cccccc')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12.0, 12.0))\n",
    "\n",
    "row,col = 3, 3\n",
    "id_res = 1\n",
    "for r in range(0,row):\n",
    "    for c in range(0,col):\n",
    "        ax = fig.add_subplot(row,col ,id_res)\n",
    "        ax.imshow( diff_NG[id_res,:,:,0] )\n",
    "        ax.tick_params(labelbottom=False, labelleft=False, direction='in')\n",
    "        mae = np.sum( diff_NG[id_res,:,:,0]) / diff_NG[id_res,:,:,0].size\n",
    "        ax.set_xlabel( '{:.3f}'.format(mae),size=15)\n",
    "        id_res = id_res + 1 # 画像ID\n",
    "plt.show()\n",
    "#plt.savefig('res_diff.png', facecolor='#cccccc')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist([arr_mae_OK,arr_mae_NG], bins=60, alpha=0.7 )\n",
    "xmin = 0; xmax = 30\n",
    "plt.vlines([th], xmin, xmax, \"blue\", linestyles='dashed',color='red')\n",
    "mean = np.mean(arr_mae_OK)\n",
    "std = np.std(arr_mae_OK)\n",
    "lower = np.min(arr_mae_OK)\n",
    "upper = np.max(arr_mae_NG)\n",
    "plt.xlim([0.015,0.04]); plt.ylim([0,30])\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(X_test_NG)):\n",
    "    plt.imsave(\"./data/res/input/input\"+str(i)+\".png\",X_test_NG[i,:,:,0])\n",
    "    plt.imsave(\"./data/res/decode/\"+str(i)+\".png\",decode_test_NG[i,:,:,0])\n",
    "    plt.imsave(\"./data/res/diff/\"+str(i)+\".png\",diff_NG[i,:,:,0])\n",
    "\n",
    "#plt.imshow(X_test[5,:,:,0])\n",
    "#plt.show()\n",
    "\n",
    "#plt.imshow(decode_test[5,:,:,0])\n",
    "#plt.show()\n",
    "\n",
    "#plt.imshow(diff_NG[5,:,:,0])\n",
    "#plt.show()\n",
    "\n",
    "resimg = diff_NG[5,:,:,0]\n",
    "\n",
    "\n",
    "orgimg = X_test_NG[5,:,:,0]\n",
    "orgimg = orgimg * 255\n",
    "\n",
    "print(resimg.shape)\n",
    "print(resimg.dtype)\n",
    "\n",
    "## 逆転画像を入力しているので，背景の分散が増す．\n",
    "\n",
    "# Data load\n",
    "data_katagawa = np.load(\"./data/capsule_OK_katahou.npy\")\n",
    "# Rescale -1 to 1\n",
    "data_katagawa = data_katagawa.astype('float32') / 255.\n",
    "data_katagawa = data_katagawa.transpose(0,2,3,1) # transpose\n",
    "\n",
    "print(\"data_katagawa.shape\", data_katagawa.shape)\n",
    "\n",
    "encode_katagawa = encoder.predict(data_katagawa)\n",
    "decode_katagawa = decoder.predict(encode_katagawa)\n",
    "\n",
    "diff_katagawa = (data_katagawa - decode_katagawa)\n",
    "diff_katagawa = np.absolute(diff_katagawa)\n",
    "\n",
    "print(diff_katagawa.shape)\n",
    "\n",
    "std_img = np.zeros( (128,128) ,dtype=float)\n",
    "mean_img = np.zeros( (128,128) ,dtype=float)\n",
    "like_img = np.zeros( (128,128) ,dtype=float)\n",
    "\n",
    "# 分散画像作成\n",
    "for y in range(diff_katagawa.shape[1]):\n",
    "    for x in range(diff_katagawa.shape[2]):        \n",
    "        std,mean = np.std( diff_katagawa[:,y,x,0] ),np.mean( diff_katagawa[:,y,x,0] )\n",
    "        std_img[y,x] = std\n",
    "        mean_img[y,x] = mean\n",
    "        like_img[y,x] = np.exp(-(x - mean)**2 / (2*std**2))\n",
    "\n",
    "plt.hist(std_img.ravel(),256,[0,0.2]); plt.show()        \n",
    "\n",
    "print(std_img.dtype)\n",
    "\n",
    "log_img = std_img.copy()\n",
    "log_img[:,:] = 1.0 / std_img[:,:]\n",
    "#log_img = like_img\n",
    "plt.imshow(std_img); plt.show()\n",
    "plt.imshow(log_img);plt.show()\n",
    "\n",
    "print(np.max(log_img))\n",
    "#plt.hist(log_img.ravel(),256,[0,100]); plt.show()        \n",
    "\n",
    "res_ok  = log_img * diff_OK[5,:,:,0]\n",
    "res_ng  = log_img * diff_NG[5,:,:,0]\n",
    "\n",
    "plt.imshow(res_ok); plt.colorbar(); plt.show()\n",
    "print(np.sum(res_ok))\n",
    "\n",
    "arr_mae_OK = []\n",
    "log_OK = diff_OK.copy()\n",
    "for i in range(len(diff_OK)):\n",
    "    log_OK[i,:,:,0] = log_img * diff_OK[i,:,:,0]\n",
    "    mae = np.sum(log_OK[i,:,:,0]) / log_OK[i,:,:,0].size\n",
    "    arr_mae_OK.append(mae)\n",
    "\n",
    "\n",
    "arr_mae_NG = []\n",
    "log_NG = diff_NG.copy()\n",
    "for i in range(len(diff_NG)):\n",
    "    log_NG[i,:,:,0] = log_img * diff_NG[i,:,:,0]\n",
    "    mae = np.sum(log_NG[i,:,:,0]) / log_NG[i,:,:,0].size\n",
    "    arr_mae_NG.append(mae)\n",
    "    \n",
    "print( len(arr_mae_OK) )\n",
    "print( len(arr_mae_NG) )\n",
    "\n",
    "plt.hist([arr_mae_OK,arr_mae_NG], bins=60, alpha=0.7 )\n",
    "\n",
    "th = np.min( np.array(arr_mae_NG) )\n",
    "print(th)\n",
    "ymin = 0; ymax = 100; plt.vlines([th], ymin, ymax, \"blue\", linestyles='dashed',color='red')\n",
    "plt.xlim([0.5,6]); plt.ylim([0,30])\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6.0, 6.0))\n",
    "\n",
    "row,col = 3, 3\n",
    "id_res = 1\n",
    "for r in range(0,row):\n",
    "    for c in range(0,col):\n",
    "        ax = fig.add_subplot(row,col ,id_res)\n",
    "        ax.imshow( log_OK[id_res,:,:,0] )\n",
    "\n",
    "        ax.tick_params(labelbottom=False, labelleft=False, direction='in')\n",
    "        mae = np.sum( log_OK[id_res,:,:,0]) / log_OK[id_res,:,:,0].size\n",
    "        ax.set_xlabel( '{:.3f}'.format(mae),size=15)\n",
    "        id_res = id_res + 1 # 画像ID\n",
    "plt.show()\n",
    "#plt.savefig('res_diff.png', facecolor='#cccccc')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(6.0, 6.0))\n",
    "\n",
    "row,col = 3, 3\n",
    "id_res = 1\n",
    "for r in range(0,row):\n",
    "    for c in range(0,col):\n",
    "        ax = fig.add_subplot(row,col ,id_res)\n",
    "        ax.imshow( log_NG[id_res,:,:,0] )\n",
    "        ax.tick_params(labelbottom=False, labelleft=False, direction='in')\n",
    "        mae = np.sum( log_NG[id_res,:,:,0]) / log_NG[id_res,:,:,0].size\n",
    "        ax.set_xlabel( '{:.3f}'.format(mae),size=15)\n",
    "        id_res = id_res + 1 # 画像ID\n",
    "plt.show()\n",
    "#plt.savefig('res_diff.png', facecolor='#cccccc')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# combine ok and ng for making true and pred\n",
    "pred = arr_mae_OK\n",
    "pred = np.append(pred,arr_mae_NG)\n",
    "\n",
    "true = np.zeros(np.array(arr_mae_OK).shape[0])\n",
    "ones = np.ones(np.array(arr_mae_NG).shape[0])\n",
    "true = np.append(true,ones)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(true, pred)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# ROC曲線をプロット\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc ,color=\"darkred\")\n",
    "plt.legend()\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# しきい値以上を1\n",
    "bin_pred = [1 if p >= th else 0 for p in pred]\n",
    "m = confusion_matrix(true, bin_pred,labels=[1,0])\n",
    "print('Confution Matrix:\\n{}'.format(m))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"threshold:{:.3f}\".format(th))\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print('Accuracy:{:.3f}'.format(accuracy_score(true, bin_pred)))\n",
    "print('Recall:{:.3f} (recall must be 1.0)'.format(recall_score(true, bin_pred)))\n",
    "print('Precision:{:.3f}'.format(precision_score(true, bin_pred)))\n",
    "print('F1-measure:{:.3f}'.format(f1_score(true, bin_pred)))\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(\"未検出率(FNR):{:.3f} (になるようにThreshold決定)\".format( m[0,1]/(m[0,1] + m[0,0]) ) )\n",
    "print(\"過検出率(FPR):{:.3f}\".format(m[1,0]/(m[1,0] + m[1,1])))\n",
    "print(\"--------------------------------------------------------------------------\")img_shape = (128,128,1)\n",
    "latent_dim = 32\n",
    "\n",
    "def make_vae(latent_size, kl_coeff=1.0):\n",
    "    \n",
    "    ## Encoder #################################################################################\n",
    "    encoder_input = keras.Input(shape=img_shape)\n",
    "    x = layers.Conv2D(8,4,padding='same',activation='relu',strides=(2,2))(encoder_input)\n",
    "    x = layers.Conv2D(16,4,padding='same',activation='relu',strides=(2,2))(x)\n",
    "    x = layers.Conv2D(24,4,padding='same',activation='relu',strides=(2,2))(x)\n",
    "    x = layers.Conv2D(32,4,padding='same',activation='relu',strides=(2,2))(x)\n",
    "    shape_before_flattening = K.int_shape(x) # フラット前の構造を保存\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    \n",
    "    z_mean = layers.Dense(latent_dim,name='z_mean')(x)\n",
    "    z_log_sigma = layers.Dense(latent_dim)(x)\n",
    "    \n",
    "    ## Latent Dim Sampling\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_sigma = args\n",
    "        epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim) , mean = 0 , stddev=1. )\n",
    "        return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "        \n",
    "    encoder = Model(encoder_input,z_mean, name='encoder') # z_mean is neccesary not z\n",
    "    encoder.summary()\n",
    "    ############################################################################################\n",
    "\n",
    "    ## Decoder #################################################################################\n",
    "    z = layers.Lambda(sampling, output_shape=(latent_size,))([z_mean, z_log_sigma])\n",
    "    decoder_input = layers.Input(K.int_shape(z)[1:])\n",
    "    x = layers.Dense(np.prod(shape_before_flattening[1:]),activation='relu')(decoder_input)\n",
    "    x = layers.Reshape(shape_before_flattening[1:])(x)\n",
    "    x = layers.Conv2DTranspose(32,4,padding='same',activation='relu',strides=(2,2) )(x)\n",
    "    x = layers.Conv2DTranspose(24,4,padding='same',activation='relu',strides=(2,2) )(x)\n",
    "    x = layers.Conv2DTranspose(16,4,padding='same',activation='relu',strides=(2,2) )(x)\n",
    "    x = layers.Conv2DTranspose(8,4,padding='same',activation='relu',strides=(2,2) )(x)\n",
    "    x = layers.Conv2D(1,3,padding='same',activation='sigmoid')(x)\n",
    "    decoder = Model(decoder_input,x)\n",
    "    decoder.summary()\n",
    "    ############################################################################################\n",
    "    \n",
    "    # define VAE\n",
    "    z_decoded = decoder(z_mean)\n",
    "    vae = Model(encoder_input,z_decoded)\n",
    "    vae.summary()\n",
    "        \n",
    "    def vae_loss(y_true, y_pred):\n",
    "        \n",
    "        recon_loss = K.sum(K.square(y_true-y_pred), axis=[1,2])\n",
    "        kl_loss = - 0.5 * K.sum(1 + 2*z_log_sigma - K.square(z_mean) - K.square(K.exp(z_log_sigma)), axis=-1)\n",
    "        return recon_loss + kl_coeff*kl_loss\n",
    "    \n",
    "    return encoder, decoder, vae, vae_loss\n",
    "\n",
    "# model定義\n",
    "encoder, decoder, vae, vae_loss = make_vae(32, kl_coeff=1.)\n",
    "vae.compile(optimizer='rmsprop', loss=vae_loss, metrics=[])\n",
    "\n",
    "data_OK = np.load(\"./data/capsule_OK_katahou.npy\")\n",
    "data_NG = np.load(\"./data/capsule_NG_yarinaosi.npy\")\n",
    "\n",
    "# scaling 0 to 1\n",
    "data_OK = data_OK.astype('float32') / 255.\n",
    "data_OK = data_OK.transpose(0,2,3,1) # transpose\n",
    "\n",
    "data_NG = data_NG.astype('float32') / 255.\n",
    "data_NG = data_NG.transpose(0,2,3,1) # transpose\n",
    "\n",
    "# train, test split\n",
    "n_train = int(data_OK.shape[0]*0.6)\n",
    "X_train = data_OK[0:n_train:]\n",
    "\n",
    "n_val = int(data_OK.shape[0]*0.2)\n",
    "X_val_OK  = data_OK[n_train:n_train+n_val:]\n",
    "X_test_OK = data_OK[n_train+n_val::]\n",
    "\n",
    "# n_test = int( len(data_NG)*0.6 )\n",
    "X_test_NG  = data_NG[:]\n",
    "\n",
    "print(\"OK sample shape\",data_OK.shape)\n",
    "print(\"X_train.shape\", X_train.shape)\n",
    "print(\"X_test_OK.shape\", X_test_OK.shape)\n",
    "print(\"X_val_OK.shape\",X_val_OK.shape)\n",
    "print(\"X_test_NG.shape\",X_test_NG.shape)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen= ImageDataGenerator(\n",
    "    #featurewise_center=True,\n",
    "    #featurewise_std_normalization=True\n",
    "    rotation_range=3, # 90°まで回転\n",
    "    width_shift_range=0.05, # 水平方向にランダムでシフト\n",
    "    #height_shift_range=0.1, # 垂直方向にランダムでシフト\n",
    "    #channel_shift_range=50.0, # 色調をランダム変更\n",
    "    #shear_range=0.39, # 斜め方向(pi/8まで)に引っ張る\n",
    "    horizontal_flip=True) # 水平方向にランダムで反転\n",
    "datagen.fit(X_train)\n",
    "\n",
    "\n",
    "_train_size = X_train.shape[0]\n",
    "_batch_size = 16\n",
    "_itr_size = 1500\n",
    "\n",
    "print('trainin_data : %d \\\n",
    "      \\nbatch_size   : %d \\\n",
    "      \\niter_size : %d \\\n",
    "      \\nvirtual_epoch : % d ' % (_train_size, _batch_size, _itr_size, _itr_size / (_train_size / _batch_size)))\n",
    "\n",
    "      itr=0\n",
    "train_loss_running,val_loss_running=0,0\n",
    "train_loss, val_loss = [],[]\n",
    "\n",
    "val_judge = float('inf') # oneday change this\n",
    "# infinite loop, so break using virtural epoch\n",
    "for x_batch in datagen.flow(x=X_train, y=None, batch_size=32,shuffle=True):\n",
    "    \n",
    "    # train using one bathc\n",
    "    result = vae.fit(x = x_batch, y=x_batch , verbose=0,validation_data=(X_val_OK,X_val_OK))\n",
    "    \n",
    "    # caluculate train_loss and val_loss\n",
    "    val_loss_running = result.history['val_loss'][0] / _batch_size\n",
    "    train_loss.append( result.history['loss'][0] / _batch_size)\n",
    "    val_loss.append( val_loss_running )\n",
    "\n",
    "    # best_model save after 80% train loop\n",
    "    if val_loss_running < val_judge and int(0.8 * _itr_size) < itr:\n",
    "        \n",
    "        print(\" model save, val_loss :\", val_loss_running)\n",
    "        val_judge = val_loss_running        \n",
    "        encoder.save('encoder_best.h5',include_optimizer=False)\n",
    "        decoder.save('decoder_best.h5',include_optimizer=False)\n",
    "    \n",
    "    \n",
    "    if itr % 100== 0:\n",
    "        print('-------------iteration-------------', itr)\n",
    "    if itr > _itr_size:\n",
    "        break\n",
    "        \n",
    "    itr = itr+1\n",
    "\n",
    "\n",
    "# load best model\n",
    "encoder_best = keras.models.load_model('encoder_best.h5', compile=False)\n",
    "decoder_best = keras.models.load_model('decoder_best.h5', compile=False)\n",
    "\n",
    "# encode and decode\n",
    "encode_test_OK = encoder_best.predict(X_test_OK)\n",
    "decode_test_OK = decoder_best.predict(encode_test_OK)\n",
    "encode_test_NG = encoder_best.predict(X_test_NG)\n",
    "decode_test_NG = decoder_best.predict(encode_test_NG)\n",
    "\n",
    "\n",
    "# plot loss and acc\n",
    "plt.plot( train_loss, label=\"training\")\n",
    "plt.plot( val_loss, label=\"validation\")\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Mean Absolute Error\n",
    "# OK\n",
    "arr_mae_OK = []\n",
    "diff_OK = (X_test_OK - decode_test_OK)\n",
    "diff_OK = np.absolute(diff_OK)\n",
    "for i in range(len(diff_OK)):\n",
    "    arr_mae_OK.append(np.sum(diff_OK[i,:,:,0] / diff_OK[i,:,:,0].size ))\n",
    "\n",
    "# NG\n",
    "arr_mae_NG = []\n",
    "diff_NG = (X_test_NG - decode_test_NG)\n",
    "diff_NG = np.absolute(diff_NG)\n",
    "for i in range(len(diff_NG)):\n",
    "    #print(np.sum(diff_NG[i,:,:,0]) , diff_NG[i,:,:,0].size )\n",
    "    arr_mae_NG.append(np.sum(diff_NG[i,:,:,0] / diff_NG[i,:,:,0].size ))\n",
    "    \n",
    "print(diff_OK[0,:,:,0].size)\n",
    "print(diff_NG[0,:,:,0].size)\n",
    "print(128*128)\n",
    "\n",
    "print( len(arr_mae_OK) )\n",
    "print( len(arr_mae_NG) )\n",
    "th = np.min(arr_mae_NG)\n",
    "print(th,np.max(arr_mae_OK))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12.0, 12.0))\n",
    "\n",
    "row,col = 3, 3\n",
    "id_res = 1\n",
    "for r in range(0,row):\n",
    "    for c in range(0,col):\n",
    "        ax = fig.add_subplot(row,col ,id_res)\n",
    "        ax.imshow( diff_OK[id_res,:,:,0] )\n",
    "        ax.tick_params(labelbottom=False, labelleft=False, direction='in')\n",
    "        mae = np.sum( diff_OK[id_res,:,:,0]) / diff_OK[id_res,:,:,0].size\n",
    "        ax.set_xlabel( '{:.3f}'.format(mae),size=15)\n",
    "        id_res = id_res + 1 # 画像ID\n",
    "plt.show()\n",
    "#plt.savefig('res_diff.png', facecolor='#cccccc')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12.0, 12.0))\n",
    "\n",
    "row,col = 3, 3\n",
    "id_res = 1\n",
    "for r in range(0,row):\n",
    "    for c in range(0,col):\n",
    "        ax = fig.add_subplot(row,col ,id_res)\n",
    "        ax.imshow( diff_NG[id_res,:,:,0] )\n",
    "        ax.tick_params(labelbottom=False, labelleft=False, direction='in')\n",
    "        mae = np.sum( diff_NG[id_res,:,:,0]) / diff_NG[id_res,:,:,0].size\n",
    "        ax.set_xlabel( '{:.3f}'.format(mae),size=15)\n",
    "        id_res = id_res + 1 # 画像ID\n",
    "plt.show()\n",
    "#plt.savefig('res_diff.png', facecolor='#cccccc')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist([arr_mae_OK,arr_mae_NG], bins=60, alpha=0.7 )\n",
    "xmin = 0; xmax = 30\n",
    "plt.vlines([th], xmin, xmax, \"blue\", linestyles='dashed',color='red')\n",
    "mean = np.mean(arr_mae_OK)\n",
    "std = np.std(arr_mae_OK)\n",
    "lower = np.min(arr_mae_OK)\n",
    "upper = np.max(arr_mae_NG)\n",
    "plt.xlim([0.015,0.04]); plt.ylim([0,30])\n",
    "plt.show()\n",
    "\n",
    "for i in range(len(X_test_NG)):\n",
    "    plt.imsave(\"./data/res/input/input\"+str(i)+\".png\",X_test_NG[i,:,:,0])\n",
    "    plt.imsave(\"./data/res/decode/\"+str(i)+\".png\",decode_test_NG[i,:,:,0])\n",
    "    plt.imsave(\"./data/res/diff/\"+str(i)+\".png\",diff_NG[i,:,:,0])\n",
    "\n",
    "#plt.imshow(X_test[5,:,:,0])\n",
    "#plt.show()\n",
    "\n",
    "#plt.imshow(decode_test[5,:,:,0])\n",
    "#plt.show()\n",
    "\n",
    "#plt.imshow(diff_NG[5,:,:,0])\n",
    "#plt.show()\n",
    "\n",
    "resimg = diff_NG[5,:,:,0]\n",
    "\n",
    "\n",
    "orgimg = X_test_NG[5,:,:,0]\n",
    "orgimg = orgimg * 255\n",
    "\n",
    "print(resimg.shape)\n",
    "print(resimg.dtype)\n",
    "\n",
    "## 逆転画像を入力しているので，背景の分散が増す．\n",
    "\n",
    "# Data load\n",
    "data_katagawa = np.load(\"./data/capsule_OK_katahou.npy\")\n",
    "# Rescale -1 to 1\n",
    "data_katagawa = data_katagawa.astype('float32') / 255.\n",
    "data_katagawa = data_katagawa.transpose(0,2,3,1) # transpose\n",
    "\n",
    "print(\"data_katagawa.shape\", data_katagawa.shape)\n",
    "\n",
    "encode_katagawa = encoder.predict(data_katagawa)\n",
    "decode_katagawa = decoder.predict(encode_katagawa)\n",
    "\n",
    "diff_katagawa = (data_katagawa - decode_katagawa)\n",
    "diff_katagawa = np.absolute(diff_katagawa)\n",
    "\n",
    "print(diff_katagawa.shape)\n",
    "\n",
    "std_img = np.zeros( (128,128) ,dtype=float)\n",
    "mean_img = np.zeros( (128,128) ,dtype=float)\n",
    "like_img = np.zeros( (128,128) ,dtype=float)\n",
    "\n",
    "# 分散画像作成\n",
    "for y in range(diff_katagawa.shape[1]):\n",
    "    for x in range(diff_katagawa.shape[2]):        \n",
    "        std,mean = np.std( diff_katagawa[:,y,x,0] ),np.mean( diff_katagawa[:,y,x,0] )\n",
    "        std_img[y,x] = std\n",
    "        mean_img[y,x] = mean\n",
    "        like_img[y,x] = np.exp(-(x - mean)**2 / (2*std**2))\n",
    "\n",
    "plt.hist(std_img.ravel(),256,[0,0.2]); plt.show()        \n",
    "\n",
    "print(std_img.dtype)\n",
    "\n",
    "log_img = std_img.copy()\n",
    "log_img[:,:] = 1.0 / std_img[:,:]\n",
    "#log_img = like_img\n",
    "plt.imshow(std_img); plt.show()\n",
    "plt.imshow(log_img);plt.show()\n",
    "\n",
    "print(np.max(log_img))\n",
    "#plt.hist(log_img.ravel(),256,[0,100]); plt.show()        \n",
    "\n",
    "res_ok  = log_img * diff_OK[5,:,:,0]\n",
    "res_ng  = log_img * diff_NG[5,:,:,0]\n",
    "\n",
    "plt.imshow(res_ok); plt.colorbar(); plt.show()\n",
    "print(np.sum(res_ok))\n",
    "\n",
    "arr_mae_OK = []\n",
    "log_OK = diff_OK.copy()\n",
    "for i in range(len(diff_OK)):\n",
    "    log_OK[i,:,:,0] = log_img * diff_OK[i,:,:,0]\n",
    "    mae = np.sum(log_OK[i,:,:,0]) / log_OK[i,:,:,0].size\n",
    "    arr_mae_OK.append(mae)\n",
    "\n",
    "\n",
    "arr_mae_NG = []\n",
    "log_NG = diff_NG.copy()\n",
    "for i in range(len(diff_NG)):\n",
    "    log_NG[i,:,:,0] = log_img * diff_NG[i,:,:,0]\n",
    "    mae = np.sum(log_NG[i,:,:,0]) / log_NG[i,:,:,0].size\n",
    "    arr_mae_NG.append(mae)\n",
    "    \n",
    "print( len(arr_mae_OK) )\n",
    "print( len(arr_mae_NG) )\n",
    "\n",
    "plt.hist([arr_mae_OK,arr_mae_NG], bins=60, alpha=0.7 )\n",
    "\n",
    "th = np.min( np.array(arr_mae_NG) )\n",
    "print(th)\n",
    "ymin = 0; ymax = 100; plt.vlines([th], ymin, ymax, \"blue\", linestyles='dashed',color='red')\n",
    "plt.xlim([0.5,6]); plt.ylim([0,30])\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(6.0, 6.0))\n",
    "\n",
    "row,col = 3, 3\n",
    "id_res = 1\n",
    "for r in range(0,row):\n",
    "    for c in range(0,col):\n",
    "        ax = fig.add_subplot(row,col ,id_res)\n",
    "        ax.imshow( log_OK[id_res,:,:,0] )\n",
    "\n",
    "        ax.tick_params(labelbottom=False, labelleft=False, direction='in')\n",
    "        mae = np.sum( log_OK[id_res,:,:,0]) / log_OK[id_res,:,:,0].size\n",
    "        ax.set_xlabel( '{:.3f}'.format(mae),size=15)\n",
    "        id_res = id_res + 1 # 画像ID\n",
    "plt.show()\n",
    "#plt.savefig('res_diff.png', facecolor='#cccccc')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(6.0, 6.0))\n",
    "\n",
    "row,col = 3, 3\n",
    "id_res = 1\n",
    "for r in range(0,row):\n",
    "    for c in range(0,col):\n",
    "        ax = fig.add_subplot(row,col ,id_res)\n",
    "        ax.imshow( log_NG[id_res,:,:,0] )\n",
    "        ax.tick_params(labelbottom=False, labelleft=False, direction='in')\n",
    "        mae = np.sum( log_NG[id_res,:,:,0]) / log_NG[id_res,:,:,0].size\n",
    "        ax.set_xlabel( '{:.3f}'.format(mae),size=15)\n",
    "        id_res = id_res + 1 # 画像ID\n",
    "plt.show()\n",
    "#plt.savefig('res_diff.png', facecolor='#cccccc')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# combine ok and ng for making true and pred\n",
    "pred = arr_mae_OK\n",
    "pred = np.append(pred,arr_mae_NG)\n",
    "\n",
    "true = np.zeros(np.array(arr_mae_OK).shape[0])\n",
    "ones = np.ones(np.array(arr_mae_NG).shape[0])\n",
    "true = np.append(true,ones)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(true, pred)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# ROC曲線をプロット\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %.2f)'%auc ,color=\"darkred\")\n",
    "plt.legend()\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.grid(True)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# しきい値以上を1\n",
    "bin_pred = [1 if p >= th else 0 for p in pred]\n",
    "m = confusion_matrix(true, bin_pred,labels=[1,0])\n",
    "print('Confution Matrix:\\n{}'.format(m))\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"threshold:{:.3f}\".format(th))\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print('Accuracy:{:.3f}'.format(accuracy_score(true, bin_pred)))\n",
    "print('Recall:{:.3f} (recall must be 1.0)'.format(recall_score(true, bin_pred)))\n",
    "print('Precision:{:.3f}'.format(precision_score(true, bin_pred)))\n",
    "print('F1-measure:{:.3f}'.format(f1_score(true, bin_pred)))\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(\"未検出率(FNR):{:.3f} (になるようにThreshold決定)\".format( m[0,1]/(m[0,1] + m[0,0]) ) )\n",
    "print(\"過検出率(FPR):{:.3f}\".format(m[1,0]/(m[1,0] + m[1,1])))\n",
    "print(\"--------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
